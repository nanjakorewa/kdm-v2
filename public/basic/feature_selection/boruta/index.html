<!DOCTYPE html>
<html lang="ja" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  Boruta
  
  #
  

Borutaを使って特徴量を選択してみます。このブロックのコードはBorutaの実行サンプルをそのまま持ってきたものです。
Kursa, Miron B., and Witold R. Rudnicki. &quot;Feature selection with the Boruta package.&quot; Journal of statistical software 36 (2010): 1-13.


  

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from boruta import BorutaPy


# FIXME
np.random.seed(777)
np.int = int
np.float = float
np.bool = bool
# load X and y
X = pd.read_csv(&#34;examples/test_X.csv&#34;, index_col=0).values
y = pd.read_csv(&#34;examples/test_y.csv&#34;, header=None, index_col=0).values
y = y.ravel()

# define random forest classifier, with utilising all cores and
# sampling in proportion to y labels
rf = RandomForestClassifier(n_jobs=-1, class_weight=&#34;balanced&#34;, max_depth=5)

# define Boruta feature selection method
feat_selector = BorutaPy(rf, n_estimators=&#34;auto&#34;, verbose=2, random_state=1)

# find all relevant features - 5 features should be selected
feat_selector.fit(X, y)

# check selected features - first 5 features are selected
feat_selector.support_

# check ranking of features
feat_selector.ranking_

# call transform() on X to filter it down to selected features
X_filtered = feat_selector.transform(X)
Iteration: 	1 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	2 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	3 / 100
Confirmed: 	0
Tentative: 	10

BorutaPy finished running.

Iteration: 	9 / 100
Confirmed: 	5
Tentative: 	0
Rejected: 	5


  人工データでの実験
  
  #
  

from sklearn.datasets import make_classification
from xgboost import XGBClassifier


def fs_by_boruta(model, X, y):
    feat_selector = BorutaPy(model, n_estimators=&#34;auto&#34;, verbose=2, random_state=1)
    feat_selector.fit(X, y)
    X_filtered = feat_selector.transform(X)

    if X.shape[1] == X_filtered.shape[1]:
        print(&#34;不用な特徴は見つかりませんでした&#34;)
    else:
        print(&#34;不用な特徴を削除しました&#34;)
        print(f&#34;{X.shape[1]} --&gt; {X_filtered.shape[1]}&#34;)

    return X_filtered

  すべて必要な特徴ならば削除しない
  
  #
  

X, y = make_classification(
    n_samples=1000,
    n_features=10,
    n_informative=10,
    n_redundant=0,
    n_repeated=0,
    n_classes=2,
    random_state=0,
    shuffle=False,
)
model = XGBClassifier(max_depth=4)
fs_by_boruta(model, X, y)
Iteration: 	1 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	2 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	3 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	4 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	5 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	6 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	7 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	8 / 100
Confirmed: 	10
Tentative: 	0
Rejected: 	0


BorutaPy finished running.

Iteration: 	9 / 100
Confirmed: 	10
Tentative: 	0
Rejected: 	0
不用な特徴は見つかりませんでした





array([[ 0.38760058, -0.4398061 ,  1.0103586 , ..., -2.11674403,
        -3.59368321, -0.43265007],
       [-2.18745511, -2.45701675,  1.99758878, ...,  1.16128752,
        -1.92766999,  3.18705784],
       [ 3.98304273,  0.06250274, -1.31136045, ...,  1.45498409,
        -4.17178063, -2.21695578],
       ...,
       [-0.44293666,  3.25707522, -0.50633794, ..., -0.72410483,
        -1.5420989 ,  0.75991518],
       [-1.12641706, -0.48636924,  0.92918889, ..., -1.01001779,
        -2.69280573, -3.47050681],
       [-2.3936814 ,  1.44048113,  1.95832126, ..., -5.15104933,
        -1.02766442,  1.4853396 ]])


  不用な特徴は削除する
  
  #
  

100個のうち10個だけ有用な特徴を混ぜて、何個削除できるかを試します。">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/basic/feature_selection/boruta/">
  <meta property="og:site_name" content="K_DM Book">
  <meta property="og:title" content="Boruta">
  <meta property="og:description" content="Boruta # Borutaを使って特徴量を選択してみます。このブロックのコードはBorutaの実行サンプルをそのまま持ってきたものです。
Kursa, Miron B., and Witold R. Rudnicki. &#34;Feature selection with the Boruta package.&#34; Journal of statistical software 36 (2010): 1-13.
import numpy as np import pandas as pd from sklearn.ensemble import RandomForestClassifier from boruta import BorutaPy # FIXME np.random.seed(777) np.int = int np.float = float np.bool = bool # load X and y X = pd.read_csv(&#34;examples/test_X.csv&#34;, index_col=0).values y = pd.read_csv(&#34;examples/test_y.csv&#34;, header=None, index_col=0).values y = y.ravel() # define random forest classifier, with utilising all cores and # sampling in proportion to y labels rf = RandomForestClassifier(n_jobs=-1, class_weight=&#34;balanced&#34;, max_depth=5) # define Boruta feature selection method feat_selector = BorutaPy(rf, n_estimators=&#34;auto&#34;, verbose=2, random_state=1) # find all relevant features - 5 features should be selected feat_selector.fit(X, y) # check selected features - first 5 features are selected feat_selector.support_ # check ranking of features feat_selector.ranking_ # call transform() on X to filter it down to selected features X_filtered = feat_selector.transform(X) Iteration: 1 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 2 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 3 / 100Confirmed: 0Tentative: 10BorutaPy finished running.Iteration: 9 / 100Confirmed: 5Tentative: 0Rejected: 5人工データでの実験 # from sklearn.datasets import make_classification from xgboost import XGBClassifier def fs_by_boruta(model, X, y): feat_selector = BorutaPy(model, n_estimators=&#34;auto&#34;, verbose=2, random_state=1) feat_selector.fit(X, y) X_filtered = feat_selector.transform(X) if X.shape[1] == X_filtered.shape[1]: print(&#34;不用な特徴は見つかりませんでした&#34;) else: print(&#34;不用な特徴を削除しました&#34;) print(f&#34;{X.shape[1]} --&gt; {X_filtered.shape[1]}&#34;) return X_filtered すべて必要な特徴ならば削除しない # X, y = make_classification( n_samples=1000, n_features=10, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, random_state=0, shuffle=False, ) model = XGBClassifier(max_depth=4) fs_by_boruta(model, X, y) Iteration: 1 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 2 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 3 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 4 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 5 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 6 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 7 / 100Confirmed: 0Tentative: 10Rejected: 0Iteration: 8 / 100Confirmed: 10Tentative: 0Rejected: 0BorutaPy finished running.Iteration: 9 / 100Confirmed: 10Tentative: 0Rejected: 0不用な特徴は見つかりませんでしたarray([[ 0.38760058, -0.4398061 , 1.0103586 , ..., -2.11674403,-3.59368321, -0.43265007],[-2.18745511, -2.45701675, 1.99758878, ..., 1.16128752,-1.92766999, 3.18705784],[ 3.98304273, 0.06250274, -1.31136045, ..., 1.45498409,-4.17178063, -2.21695578],...,[-0.44293666, 3.25707522, -0.50633794, ..., -0.72410483,-1.5420989 , 0.75991518],[-1.12641706, -0.48636924, 0.92918889, ..., -1.01001779,-2.69280573, -3.47050681],[-2.3936814 , 1.44048113, 1.95832126, ..., -5.15104933,-1.02766442, 1.4853396 ]])不用な特徴は削除する # 100個のうち10個だけ有用な特徴を混ぜて、何個削除できるかを試します。">
  <meta property="og:locale" content="ja">
  <meta property="og:type" content="article">
    <meta property="article:section" content="basic">
<title>Boruta | K_DM Book</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="http://localhost:1313/basic/feature_selection/boruta/">
  <link rel="alternate" hreflang="es" href="http://localhost:1313/es/basic/feature_selection/boruta/" title="Boruta">
  <link rel="alternate" hreflang="id" href="http://localhost:1313/id/basic/feature_selection/boruta/" title="Boruta">
<link rel="stylesheet" href="/book.min.5c80a20e1f11b0e9dc4cae70ce44083860ffa999a7bf8ab5dab38664fde8a418.css" integrity="sha256-XICiDh8RsOncTK5wzkQIOGD/qZmnv4q12rOGZP3opBg=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/ja.search.min.58d3a47dfc146864a58893dc5fc3dea0c3290cbd2695f142a0697316f5b64e98.js" integrity="sha256-WNOkffwUaGSliJPcX8PeoMMpDL0mlfFCoGlzFvW2Tpg=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr" class="book-kind-page book-type-basic">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    
<aside class="book-menu">
  <div class="book-menu-content">
    
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>K_DM Book</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="検索" aria-label="検索" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>



  



  
    
  
    
  
    
  


  

  


<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex">
      <a role="button" class="flex flex-auto">
        <img src="/svg/translate.svg" class="book-icon" alt="Languages" />
        <span>日本語</span>
      </a>
    </label>

    <ul>
      
      <li>
        <a href="/en/">
          <span>English</span>
        </a>
      </li>
      
      <li>
        <a href="/es/basic/feature_selection/boruta/">
          <span>Español</span>
        </a>
      </li>
      
      <li>
        <a href="/id/basic/feature_selection/boruta/">
          <span>Indonesia</span>
        </a>
      </li>
      
    </ul>
  </li>
</ul>














  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/regression/" class="">線形回帰</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/regression/linear_regression/" class="">最小二乗法</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/regression/ridge_and_lasso/" class="">リッジ回帰・ラッソ回帰</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/regression/robust_regression/" class="">外れ値と頑健性</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/regression/regressionanalysis/" class="">残差の分析</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/classification/" class="">線形分類</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/classification/logistic_regression/" class="">ロジスティック回帰</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/classification/linear_discriminant_analysis/" class="">判別分析</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/tree/" class="">決定木</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/tree/decision_tree_classifier/" class="">決定木(分類)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/tree/decision_tree_regressor/" class="">決定木(回帰)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/tree/parameter/" class="">決定木のパラメータ</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/tree/rulefit/" class="">RuleFit</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/ensemble/" class="">アンサンブル</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/ensemble/randomforest/" class="">ランダムフォレスト</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/ensemble/stucking/" class="">スタッキング</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/ensemble/adaboost_classification/" class="">Adaboost(分類)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/ensemble/adaboost_regression/" class="">Adaboost(回帰)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/ensemble/gradient_boosting1/" class="">勾配ブースティング</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/ensemble/gradient_boosting2/" class="">勾配ブースティングの可視化</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/clustering/" class="">クラスタリング</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/clustering/k-means1/" class="">k-means</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/clustering/k-means2/" class="">k-means&#43;&#43;</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/clustering/x-means/" class="">X-means</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/dimensionality_reduction/" class="">次元削減</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/dimensionality_reduction/pca/" class="">PCA</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/dimensionality_reduction/svd/" class="">SVD</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/dimensionality_reduction/lda/" class="">LDA</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/dimensionality_reduction/kernel-pca/" class="">Kernel-PCA</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/feature_selection/" class="">特徴選択</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/feature_selection/boruta/" class="active">Boruta</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/timeseries/" class="">時系列</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/timeseries/prophet/" class="">Prophetを使ってみる</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/anomaly/" class="">異常検知</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/basic/anomaly/adtk1/" class="">異常検知①</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/basic/anomaly/adtk2/" class="">異常検知②</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>



  </div>
</aside>
 

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Boruta</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#boruta">Boruta</a></li>
    <li><a href="#人工データでの実験">人工データでの実験</a>
      <ul>
        <li><a href="#すべて必要な特徴ならば削除しない">すべて必要な特徴ならば削除しない</a></li>
        <li><a href="#不用な特徴は削除する">不用な特徴は削除する</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h2 id="boruta">
  Boruta
  
  <a class="anchor" href="#boruta">#</a>
  
</h2>
<p>Borutaを使って特徴量を選択してみます。このブロックのコードはBorutaの実行サンプルをそのまま持ってきたものです。</p>
<p><code>Kursa, Miron B., and Witold R. Rudnicki. &quot;Feature selection with the Boruta package.&quot; Journal of statistical software 36 (2010): 1-13.</code></p>

<div class="youtube-embed">
  <iframe loading="lazy" class="youtube-video" src="https://www.youtube.com/embed/xOkKnsqhUgw" title="YouTube video player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestClassifier
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> boruta <span style="color:#f92672">import</span> BorutaPy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># FIXME</span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">777</span>)
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>int <span style="color:#f92672">=</span> int
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>float <span style="color:#f92672">=</span> float
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>bool <span style="color:#f92672">=</span> bool
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># load X and y</span>
</span></span><span style="display:flex;"><span>X <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#34;examples/test_X.csv&#34;</span>, index_col<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>values
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#34;examples/test_y.csv&#34;</span>, header<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>, index_col<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>values
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> y<span style="color:#f92672">.</span>ravel()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># define random forest classifier, with utilising all cores and</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># sampling in proportion to y labels</span>
</span></span><span style="display:flex;"><span>rf <span style="color:#f92672">=</span> RandomForestClassifier(n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, class_weight<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;balanced&#34;</span>, max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># define Boruta feature selection method</span>
</span></span><span style="display:flex;"><span>feat_selector <span style="color:#f92672">=</span> BorutaPy(rf, n_estimators<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;auto&#34;</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># find all relevant features - 5 features should be selected</span>
</span></span><span style="display:flex;"><span>feat_selector<span style="color:#f92672">.</span>fit(X, y)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># check selected features - first 5 features are selected</span>
</span></span><span style="display:flex;"><span>feat_selector<span style="color:#f92672">.</span>support_
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># check ranking of features</span>
</span></span><span style="display:flex;"><span>feat_selector<span style="color:#f92672">.</span>ranking_
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># call transform() on X to filter it down to selected features</span>
</span></span><span style="display:flex;"><span>X_filtered <span style="color:#f92672">=</span> feat_selector<span style="color:#f92672">.</span>transform(X)
</span></span></code></pre></div><pre><code>Iteration: 	1 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	2 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	3 / 100
Confirmed: 	0
Tentative: 	10

BorutaPy finished running.

Iteration: 	9 / 100
Confirmed: 	5
Tentative: 	0
Rejected: 	5
</code></pre>
<h2 id="人工データでの実験">
  人工データでの実験
  
  <a class="anchor" href="#%e4%ba%ba%e5%b7%a5%e3%83%87%e3%83%bc%e3%82%bf%e3%81%a7%e3%81%ae%e5%ae%9f%e9%a8%93">#</a>
  
</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_classification
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> xgboost <span style="color:#f92672">import</span> XGBClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fs_by_boruta</span>(model, X, y):
</span></span><span style="display:flex;"><span>    feat_selector <span style="color:#f92672">=</span> BorutaPy(model, n_estimators<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;auto&#34;</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    feat_selector<span style="color:#f92672">.</span>fit(X, y)
</span></span><span style="display:flex;"><span>    X_filtered <span style="color:#f92672">=</span> feat_selector<span style="color:#f92672">.</span>transform(X)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> X<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">==</span> X_filtered<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>]:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;不用な特徴は見つかりませんでした&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;不用な特徴を削除しました&#34;</span>)
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>X<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74"> --&gt; </span><span style="color:#e6db74">{</span>X_filtered<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> X_filtered
</span></span></code></pre></div><h3 id="すべて必要な特徴ならば削除しない">
  すべて必要な特徴ならば削除しない
  
  <a class="anchor" href="#%e3%81%99%e3%81%b9%e3%81%a6%e5%bf%85%e8%a6%81%e3%81%aa%e7%89%b9%e5%be%b4%e3%81%aa%e3%82%89%e3%81%b0%e5%89%8a%e9%99%a4%e3%81%97%e3%81%aa%e3%81%84">#</a>
  
</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> make_classification(
</span></span><span style="display:flex;"><span>    n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>,
</span></span><span style="display:flex;"><span>    n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>    n_informative<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>    n_redundant<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    n_repeated<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    n_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> XGBClassifier(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>fs_by_boruta(model, X, y)
</span></span></code></pre></div><pre><code>Iteration: 	1 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	2 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	3 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	4 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	5 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	6 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	7 / 100
Confirmed: 	0
Tentative: 	10
Rejected: 	0
Iteration: 	8 / 100
Confirmed: 	10
Tentative: 	0
Rejected: 	0


BorutaPy finished running.

Iteration: 	9 / 100
Confirmed: 	10
Tentative: 	0
Rejected: 	0
不用な特徴は見つかりませんでした





array([[ 0.38760058, -0.4398061 ,  1.0103586 , ..., -2.11674403,
        -3.59368321, -0.43265007],
       [-2.18745511, -2.45701675,  1.99758878, ...,  1.16128752,
        -1.92766999,  3.18705784],
       [ 3.98304273,  0.06250274, -1.31136045, ...,  1.45498409,
        -4.17178063, -2.21695578],
       ...,
       [-0.44293666,  3.25707522, -0.50633794, ..., -0.72410483,
        -1.5420989 ,  0.75991518],
       [-1.12641706, -0.48636924,  0.92918889, ..., -1.01001779,
        -2.69280573, -3.47050681],
       [-2.3936814 ,  1.44048113,  1.95832126, ..., -5.15104933,
        -1.02766442,  1.4853396 ]])
</code></pre>
<h3 id="不用な特徴は削除する">
  不用な特徴は削除する
  
  <a class="anchor" href="#%e4%b8%8d%e7%94%a8%e3%81%aa%e7%89%b9%e5%be%b4%e3%81%af%e5%89%8a%e9%99%a4%e3%81%99%e3%82%8b">#</a>
  
</h3>
<p>100個のうち10個だけ有用な特徴を混ぜて、何個削除できるかを試します。</p>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html">sklearn.datasets.make_classification</a>の仕様は</p>

<blockquote class='book-hint '>
  <p>Without shuffling, X horizontally stacks features in the following order: the primary n_informative features, followed by n_redundant linear combinations of the informative features, followed by n_repeated duplicates, drawn randomly with replacement from the informative and redundant features. The remaining features are filled with random noise. Thus, without shuffling, all useful features are contained in the columns X[:, :n_informative + n_redundant + n_repeated].</p>
</blockquote><p>となっているので、有用な特徴である先頭の10個の列が削除されていないかどうか確認してみます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> make_classification(
</span></span><span style="display:flex;"><span>    n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">2000</span>,
</span></span><span style="display:flex;"><span>    n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>,
</span></span><span style="display:flex;"><span>    n_informative<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>    n_redundant<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    n_repeated<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    n_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> XGBClassifier(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_b <span style="color:#f92672">=</span> fs_by_boruta(model, X, y)
</span></span></code></pre></div><pre><code>Iteration: 	1 / 100
Confirmed: 	0
Tentative: 	100
Rejected: 	0
Iteration: 	2 / 100
</code></pre>
<p>&hellip;</p>
<pre><code>BorutaPy finished running.

Iteration: 	100 / 100
Confirmed: 	10
Tentative: 	1
Rejected: 	88
不用な特徴を削除しました
100 --&gt; 10
</code></pre>
<h4 id="フィルタリング後のデータに有用な特徴が残っていることを確認する">
  フィルタリング後のデータに有用な特徴が残っていることを確認する
  
  <a class="anchor" href="#%e3%83%95%e3%82%a3%e3%83%ab%e3%82%bf%e3%83%aa%e3%83%b3%e3%82%b0%e5%be%8c%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e3%81%ab%e6%9c%89%e7%94%a8%e3%81%aa%e7%89%b9%e5%be%b4%e3%81%8c%e6%ae%8b%e3%81%a3%e3%81%a6%e3%81%84%e3%82%8b%e3%81%93%e3%81%a8%e3%82%92%e7%a2%ba%e8%aa%8d%e3%81%99%e3%82%8b">#</a>
  
</h4>
<p>期待どおりならば先頭10列は有用な特徴なのですべて残っているはずです。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>X[:, :<span style="color:#ae81ff">10</span>] <span style="color:#f92672">==</span> X_b[:, :<span style="color:#ae81ff">10</span>]
</span></span></code></pre></div><pre><code>array([[ True,  True,  True, ...,  True,  True,  True],
       [ True,  True,  True, ...,  True,  True,  True],
       [ True,  True,  True, ...,  True,  True,  True],
       ...,
       [ True,  True,  True, ...,  True,  True,  True],
       [ True,  True,  True, ...,  True,  True,  True],
       [ True,  True,  True, ...,  True,  True,  True]])
</code></pre>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>





  
  
  
  <div class="flex flex-wrap justify-between">
    <span>
    
      <a href="/basic/feature_selection/" class="flex align-center book-icon">
        <img src="/svg/backward.svg" class="book-icon" alt="Previous" title="特徴選択" />
        <span>特徴選択</span>
      </a>
    
    </span>
    <span>
    
      <a href="/basic/timeseries/" class="flex align-center book-icon">
        <span>時系列</span>
        <img src="/svg/forward.svg" class="book-icon" alt="Next" title="時系列" />
      </a>
    
    </span>
  </div>
  




  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 
      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    

<aside class="book-toc">
  <div class="book-toc-content">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#boruta">Boruta</a></li>
    <li><a href="#人工データでの実験">人工データでの実験</a>
      <ul>
        <li><a href="#すべて必要な特徴ならば削除しない">すべて必要な特徴ならば削除しない</a></li>
        <li><a href="#不用な特徴は削除する">不用な特徴は削除する</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </div>
</aside>

 
  </main>

  
</body>
</html>
















