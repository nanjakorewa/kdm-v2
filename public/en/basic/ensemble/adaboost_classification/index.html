<!DOCTYPE html>
<html lang="en" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="import matplotlib.pyplot as plt
import japanize_matplotlib
import numpy as np

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier

  Create data for experiment
  
  #
  

n_features = 20
X, y = make_classification(
    n_samples=2500,
    n_features=n_features,
    n_informative=10,
    n_classes=2,
    n_redundant=4,
    n_clusters_per_class=5,
)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.33, random_state=42
)

  Train adaboost
  
  #
  

Here we use a decision tree as a weak learner.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/en/basic/ensemble/adaboost_classification/">
  <meta property="og:site_name" content="K_DM Book">
  <meta property="og:title" content="Adaboost (classification)">
  <meta property="og:description" content="import matplotlib.pyplot as plt import japanize_matplotlib import numpy as np from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split from sklearn.metrics import roc_auc_score from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import AdaBoostClassifier Create data for experiment # n_features = 20 X, y = make_classification( n_samples=2500, n_features=n_features, n_informative=10, n_classes=2, n_redundant=4, n_clusters_per_class=5, ) X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42 ) Train adaboost # Here we use a decision tree as a weak learner.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="basic">
<title>Adaboost (classification) | K_DM Book</title>
<link rel="icon" href="/favicon.png" >
<link rel="manifest" href="/manifest.json">
<link rel="canonical" href="http://localhost:1313/en/basic/ensemble/adaboost_classification/">
  <link rel="alternate" hreflang="ja" href="http://localhost:1313/basic/ensemble/adaboost_classification/" title="Adaboost(分類)">
  <link rel="alternate" hreflang="es" href="http://localhost:1313/es/basic/ensemble/adaboost_classification/" title="Adaboost (clasificación)">
  <link rel="alternate" hreflang="id" href="http://localhost:1313/id/basic/ensemble/adaboost_classification/" title="Adaboost (klasifikasi)">
<link rel="stylesheet" href="/book.min.5c80a20e1f11b0e9dc4cae70ce44083860ffa999a7bf8ab5dab38664fde8a418.css" integrity="sha256-XICiDh8RsOncTK5wzkQIOGD/qZmnv4q12rOGZP3opBg=" crossorigin="anonymous">
  <script defer src="/fuse.min.js"></script>
  <script defer src="/en.search.min.8a44fa1abc5451ced25c796dc6ff27eb2d840fda90401b31bc09e7864db39f2e.js" integrity="sha256-ikT6GrxUUc7SXHltxv8n6y2ED9qQQBsxvAnnhk2zny4=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr" class="book-kind-page book-type-basic">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    
<aside class="book-menu">
  <div class="book-menu-content">
    
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/en/"><span>K_DM Book</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>



  



  
    
  
    
  
    
  


  

  

  


<ul class="book-languages">
  <li>
    <input type="checkbox" id="languages" class="toggle" />
    <label for="languages" class="flex">
      <a role="button" class="flex flex-auto">
        <img src="/svg/translate.svg" class="book-icon" alt="Languages" />
        <span>English</span>
      </a>
    </label>

    <ul>
      
      <li>
        <a href="/basic/ensemble/adaboost_classification/">
          <span>日本語</span>
        </a>
      </li>
      
      <li>
        <a href="/es/basic/ensemble/adaboost_classification/">
          <span>Español</span>
        </a>
      </li>
      
      <li>
        <a href="/id/basic/ensemble/adaboost_classification/">
          <span>Indonesia</span>
        </a>
      </li>
      
    </ul>
  </li>
</ul>














  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/regression/" class="">Linear Regression</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/regression/linear_regression/" class="">Least-squares method</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/regression/ridge_and_lasso/" class="">Ridge and Lasso regression</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/regression/robust_regression/" class="">Outliers and Robustness</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/classification/" class="">Linear Classification</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/classification/logistic_regression/" class="">Logistic Regression</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/classification/linear_discriminant_analysis/" class="">Linear Discriminant Analysis</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/tree/" class="">Decision Tree</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/tree/decision_tree_classifier/" class="">Decision Tree (Classification)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/tree/decision_tree_regressor/" class="">Decision tree (regression)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/tree/parameter/" class="">Decision Tree Parameters</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/ensemble/" class="">Ensemble</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/ensemble/randomforest/" class="">Random Forests</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/ensemble/stucking/" class="">Stacking</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/ensemble/adaboost_classification/" class="active">Adaboost (classification)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/ensemble/adaboost_regression/" class="">Adaboost(Regression)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/ensemble/gradient_boosting1/" class="">Gradient boosting</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/clustering/" class="">Clustering</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/clustering/k-means1/" class="">k-means</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/clustering/k-means2/" class="">k-means&#43;&#43;</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/clustering/x-means/" class="">X-means</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/dimensionality_reduction/" class="">Dimensionality Reduction</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/dimensionality_reduction/pca/" class="">PCA</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/dimensionality_reduction/svd/" class="">SVD</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/dimensionality_reduction/lda/" class="">LDA</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/dimensionality_reduction/kernel-pca/" class="">Kernel-PCA</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/feature_selection/" class="">Feature Selection</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/timeseries/" class="">Time Series</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/timeseries/prophet/" class="">Using Prophet</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/anomaly/" class="">Anomaly detection</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/en/basic/anomaly/adtk1/" class="">Anomaly Detection ①</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/en/basic/anomaly/adtk2/" class="">Anomaly Detection②</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>



  </div>
</aside>
 

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Adaboost (classification)</h3>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#create-data-for-experiment">Create data for experiment</a></li>
    <li><a href="#train-adaboost">Train adaboost</a>
      <ul>
        <li><a href="#influence-of-learning-rate">Influence of learning-rate</a></li>
      </ul>
    </li>
    <li><a href="#influence-of-n_estimators">Influence of n_estimators</a>
      <ul>
        <li><a href="#influence-of-base-estimator">Influence of base-estimator</a></li>
      </ul>
    </li>
    <li><a href="#visualization-of-data-weights-in-adaboost">Visualization of data weights in Adaboost</a>
      <ul>
        <li><a href="#weight-after-booting-has-progressed">Weight after booting has progressed</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> japanize_matplotlib
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> make_classification
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> roc_auc_score
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.tree <span style="color:#f92672">import</span> DecisionTreeClassifier
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> AdaBoostClassifier
</span></span></code></pre></div><h2 id="create-data-for-experiment">
  Create data for experiment
  
  <a class="anchor" href="#create-data-for-experiment">#</a>
  
</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>n_features <span style="color:#f92672">=</span> <span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span>X, y <span style="color:#f92672">=</span> make_classification(
</span></span><span style="display:flex;"><span>    n_samples<span style="color:#f92672">=</span><span style="color:#ae81ff">2500</span>,
</span></span><span style="display:flex;"><span>    n_features<span style="color:#f92672">=</span>n_features,
</span></span><span style="display:flex;"><span>    n_informative<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>    n_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    n_redundant<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>,
</span></span><span style="display:flex;"><span>    n_clusters_per_class<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(
</span></span><span style="display:flex;"><span>    X, y, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.33</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h2 id="train-adaboost">
  Train adaboost
  
  <a class="anchor" href="#train-adaboost">#</a>
  
</h2>
<p>Here we use a decision tree as a weak learner.</p>

<div class="notices document" ><p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html">sklearn.ensemble.StackingClassifier</a></p>
</div>

<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>ab_clf <span style="color:#f92672">=</span> AdaBoostClassifier(
</span></span><span style="display:flex;"><span>    n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>    learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>,
</span></span><span style="display:flex;"><span>    random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">117117</span>,
</span></span><span style="display:flex;"><span>    base_estimator<span style="color:#f92672">=</span>DecisionTreeClassifier(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>ab_clf<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> ab_clf<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>ab_clf_score <span style="color:#f92672">=</span> roc_auc_score(y_test, y_pred)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ab_clf_score
</span></span></code></pre></div><pre><code>0.7546477034876885
</code></pre>
<h3 id="influence-of-learning-rate">
  Influence of learning-rate
  
  <a class="anchor" href="#influence-of-learning-rate">#</a>
  
</h3>
<p>The smaller the learning-rate, the smaller the range of weight updates. Conversely, if it is too large, convergence may not occur.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scores <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>learning_rate_list <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> lr <span style="color:#f92672">in</span> learning_rate_list:
</span></span><span style="display:flex;"><span>    ab_clf_i <span style="color:#f92672">=</span> AdaBoostClassifier(
</span></span><span style="display:flex;"><span>        n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>        learning_rate<span style="color:#f92672">=</span>lr,
</span></span><span style="display:flex;"><span>        random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">117117</span>,
</span></span><span style="display:flex;"><span>        base_estimator<span style="color:#f92672">=</span>DecisionTreeClassifier(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    ab_clf_i<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    y_pred <span style="color:#f92672">=</span> ab_clf_i<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>    scores<span style="color:#f92672">.</span>append(roc_auc_score(y_test, y_pred))
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(learning_rate_list, scores)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;learning rate&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;ROC-AUC&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/basic/ensemble/Adaboost_Classification_files/Adaboost_Classification_10_0.png" alt="png" /></p>
<h2 id="influence-of-n_estimators">
  Influence of n_estimators
  
  <a class="anchor" href="#influence-of-n_estimators">#</a>
  
</h2>
<p>N_estimators specifies the number of weak learners.
Normally, there is no need to make this parameter larger or smaller.
Fix n_estimators at some large number and then adjust the other parameters.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scores <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>n_estimators_list <span style="color:#f92672">=</span> [int(ne) <span style="color:#66d9ef">for</span> ne <span style="color:#f92672">in</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">40</span>)]
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> n_estimators <span style="color:#f92672">in</span> n_estimators_list:
</span></span><span style="display:flex;"><span>    ab_clf_i <span style="color:#f92672">=</span> AdaBoostClassifier(
</span></span><span style="display:flex;"><span>        n_estimators<span style="color:#f92672">=</span>int(n_estimators),
</span></span><span style="display:flex;"><span>        learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>,
</span></span><span style="display:flex;"><span>        random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">117117</span>,
</span></span><span style="display:flex;"><span>        base_estimator<span style="color:#f92672">=</span>DecisionTreeClassifier(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    ab_clf_i<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    y_pred <span style="color:#f92672">=</span> ab_clf_i<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>    scores<span style="color:#f92672">.</span>append(roc_auc_score(y_test, y_pred))
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(n_estimators_list, scores)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;n_estimators&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;ROC-AUC&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/basic/ensemble/Adaboost_Classification_files/Adaboost_Classification_13_0.png" alt="png" /></p>
<h3 id="influence-of-base-estimator">
  Influence of base-estimator
  
  <a class="anchor" href="#influence-of-base-estimator">#</a>
  
</h3>
<p><code>base_estimator</code> specifies what to use as a weak learner. In other words, it is one of the most important parameters in Adaboost.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>scores <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>base_estimator_list <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    DecisionTreeClassifier(max_depth<span style="color:#f92672">=</span>md) <span style="color:#66d9ef">for</span> md <span style="color:#f92672">in</span> [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">10</span>]
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> base_estimator <span style="color:#f92672">in</span> base_estimator_list:
</span></span><span style="display:flex;"><span>    ab_clf_i <span style="color:#f92672">=</span> AdaBoostClassifier(
</span></span><span style="display:flex;"><span>        n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>        learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>,
</span></span><span style="display:flex;"><span>        random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">117117</span>,
</span></span><span style="display:flex;"><span>        base_estimator<span style="color:#f92672">=</span>base_estimator,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    ab_clf_i<span style="color:#f92672">.</span>fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    y_pred <span style="color:#f92672">=</span> ab_clf_i<span style="color:#f92672">.</span>predict(X_test)
</span></span><span style="display:flex;"><span>    scores<span style="color:#f92672">.</span>append(roc_auc_score(y_test, y_pred))
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>plt_index <span style="color:#f92672">=</span> [i <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(base_estimator_list))]
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>bar(plt_index, scores)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xticks(plt_index, [str(bm) <span style="color:#66d9ef">for</span> bm <span style="color:#f92672">in</span> base_estimator_list], rotation<span style="color:#f92672">=</span><span style="color:#ae81ff">90</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;base_estimator&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;ROC-AUC&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/basic/ensemble/Adaboost_Classification_files/Adaboost_Classification_16_0.png" alt="png" /></p>
<h2 id="visualization-of-data-weights-in-adaboost">
  Visualization of data weights in Adaboost
  
  <a class="anchor" href="#visualization-of-data-weights-in-adaboost">#</a>
  
</h2>
<p>Visualize assigning weights to data that is difficult to classify.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># NOTE: Model created to check the sample_weight passed to the model</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># This DummyClassifier does not change the parameters of the Adaboost</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DummyClassifier</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">__init__</span>(self):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> DecisionTreeClassifier(max_depth<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>n_classes_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>classes_ <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#34;A&#34;</span>, <span style="color:#e6db74">&#34;B&#34;</span>]
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>sample_weight <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>  <span style="color:#75715e">## sample_weight</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">fit</span>(self, X, y, sample_weight<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>sample_weight <span style="color:#f92672">=</span> sample_weight
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>fit(X, y, sample_weight<span style="color:#f92672">=</span>sample_weight)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">predict</span>(self, X, check_input<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>        proba <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>predict(X)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> proba
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_params</span>(self, deep<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">set_params</span>(self, deep<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n_samples <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>X_2, y_2 <span style="color:#f92672">=</span> make_classification(
</span></span><span style="display:flex;"><span>    n_samples<span style="color:#f92672">=</span>n_samples,
</span></span><span style="display:flex;"><span>    n_features<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    n_informative<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    n_redundant<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    n_repeated<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>    random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">117</span>,
</span></span><span style="display:flex;"><span>    n_clusters_per_class<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(
</span></span><span style="display:flex;"><span>    figsize<span style="color:#f92672">=</span>(
</span></span><span style="display:flex;"><span>        <span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Scatter plots of sample data&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(X_2[:, <span style="color:#ae81ff">0</span>], X_2[:, <span style="color:#ae81ff">1</span>], c<span style="color:#f92672">=</span>y_2)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/basic/ensemble/Adaboost_Classification_files/Adaboost_Classification_18_0.png" alt="png" /></p>
<h3 id="weight-after-booting-has-progressed">
  Weight after booting has progressed
  
  <a class="anchor" href="#weight-after-booting-has-progressed">#</a>
  
</h3>
<p>The more weighted data is represented by a larger circle.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>clf <span style="color:#f92672">=</span> AdaBoostClassifier(
</span></span><span style="display:flex;"><span>    n_estimators<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, algorithm<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;SAMME&#34;</span>, base_estimator<span style="color:#f92672">=</span>DummyClassifier()
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>clf<span style="color:#f92672">.</span>fit(X_2, y_2)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, estimators_i <span style="color:#f92672">in</span> enumerate(clf<span style="color:#f92672">.</span>estimators_):
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>figure(
</span></span><span style="display:flex;"><span>        figsize<span style="color:#f92672">=</span>(
</span></span><span style="display:flex;"><span>            <span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Visualization of the </span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">-th weighted sample&#34;</span>)
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>scatter(
</span></span><span style="display:flex;"><span>        X_2[:, <span style="color:#ae81ff">0</span>],
</span></span><span style="display:flex;"><span>        X_2[:, <span style="color:#ae81ff">1</span>],
</span></span><span style="display:flex;"><span>        marker<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;o&#34;</span>,
</span></span><span style="display:flex;"><span>        c<span style="color:#f92672">=</span>y_2,
</span></span><span style="display:flex;"><span>        alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.4</span>,
</span></span><span style="display:flex;"><span>        s<span style="color:#f92672">=</span>estimators_i<span style="color:#f92672">.</span>sample_weight <span style="color:#f92672">*</span> n_samples <span style="color:#f92672">**</span> <span style="color:#ae81ff">1.65</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/images/basic/ensemble/Adaboost_Classification_files/Adaboost_Classification_20_0.png" alt="png" /></p>
<p><img src="/images/basic/ensemble/Adaboost_Classification_files/Adaboost_Classification_20_1.png" alt="png" /></p>
<p><img src="/images/basic/ensemble/Adaboost_Classification_files/Adaboost_Classification_20_2.png" alt="png" /></p>
<p><img src="/images/basic/ensemble/Adaboost_Classification_files/Adaboost_Classification_20_3.png" alt="png" /></p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>





  
  
  
  <div class="flex flex-wrap justify-between">
    <span>
    
      <a href="/en/basic/ensemble/stucking/" class="flex align-center book-icon">
        <img src="/svg/backward.svg" class="book-icon" alt="Previous" title="Stacking" />
        <span>Stacking</span>
      </a>
    
    </span>
    <span>
    
      <a href="/en/basic/ensemble/adaboost_regression/" class="flex align-center book-icon">
        <span>Adaboost(Regression)</span>
        <img src="/svg/forward.svg" class="book-icon" alt="Next" title="Adaboost(Regression)" />
      </a>
    
    </span>
  </div>
  




  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 
      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    

<aside class="book-toc">
  <div class="book-toc-content">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#create-data-for-experiment">Create data for experiment</a></li>
    <li><a href="#train-adaboost">Train adaboost</a>
      <ul>
        <li><a href="#influence-of-learning-rate">Influence of learning-rate</a></li>
      </ul>
    </li>
    <li><a href="#influence-of-n_estimators">Influence of n_estimators</a>
      <ul>
        <li><a href="#influence-of-base-estimator">Influence of base-estimator</a></li>
      </ul>
    </li>
    <li><a href="#visualization-of-data-weights-in-adaboost">Visualization of data weights in Adaboost</a>
      <ul>
        <li><a href="#weight-after-booting-has-progressed">Weight after booting has progressed</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </div>
</aside>

 
  </main>

  
</body>
</html>
















