---
title: 線形回帰
weight: 1
chapter: true
not_use_colab: true
not_use_twitter: true
pre: "<b>2.1 </b>"
---

# 線形回帰

<div class="pagetop-box">
  <p><b>線形回帰</b>は、機械学習や統計学で最も基本的な手法のひとつです。  
  入力（説明変数）と出力（目的変数）の関係を「直線」や「平面」で近似し、将来の値を予測したり、変数間の関係を理解するのに使われます。</p>
</div>

---

## なぜ線形回帰を学ぶのか？

- 数学的にシンプルで理解しやすい  
- 実装が容易で計算量も少ない  
- 「予測」と「解釈」の両方に使える  
- 多くの発展的手法（リッジ回帰、ラッソ回帰、一般化線形モデル、ニューラルネットワークなど）の基礎になる  

---

## 線形回帰でできること

- **予測**：  
  例）広告費から売上を予測する、勉強時間からテストの点数を予測する  
- **関係性の理解**：  
  係数を調べることで「入力が1単位増えると出力がどのくらい変化するか」を解釈できる  
- **特徴量の重要度を把握**：  
  どの説明変数が予測に効いているかを確認できる  

---

## 学ぶ内容の流れ

この章では以下を学んでいきます。

1. **最小二乗法**  
   データに最もよくフィットする直線の求め方  
2. **リッジ回帰・ラッソ回帰**  
   過学習を防ぐための「正則化」の考え方  
3. **外れ値に強い回帰（Huber回帰など）**  
   データがきれいでない現実の状況にどう対応するか  

---

## まとめ

- 線形回帰は「もっとも基本的で、もっとも応用範囲が広い」機械学習モデルです。  
- 直線というシンプルな形を使いますが、実務でも広く利用されています。  
- これから学ぶ内容は、後のより高度なモデル（決定木・SVM・ニューラルネット）の理解にも役立ちます。  

---
