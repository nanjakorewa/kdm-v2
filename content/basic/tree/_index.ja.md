---
title: 決定木
weight: 4
chapter: true
not_use_colab: true
not_use_twitter: true
pre: "<b>2.3 </b>"
---

### Chapter 3

# 決定木

<div class="pagetop-box">
  <p><b>決定木（Decision Tree）</b>は、もっとも基本的で直感的に理解しやすい機械学習モデルのひとつです。データを「もし〜なら〜」というルールで分割し、最終的に予測値やクラスを決める仕組みを持っています。</p>
</div>

---

## なぜ決定木を学ぶのか？

- **木構造で表現できる**  
  データを特徴量に基づいて繰り返し分割し、その結果を木の形で表します。ルートから枝分かれし、最後に到達する「葉」が予測値（またはクラス）を表します。  

- **直感的な理解のしやすさ**  
  数学的な難解さは少なく、「もし特徴量Aが閾値Xより大きければ左へ、小さければ右へ」というルールの積み重ねです。これにより「なぜその予測になったのか？」を説明しやすいモデルです。  

- **分類にも回帰にも使える**  
  決定木はカテゴリを分ける「分類」だけでなく、連続値を予測する「回帰」にも使えます。用途が広いことから、機械学習の入門モデルとして人気があります。  

- **過学習しやすい点に注意**  
  木を深く成長させすぎると、データに合わせ込みすぎて汎化性能（未知データへの適応力）が下がることがあります。このため、木の深さや葉の数を制御するパラメータの調整が重要です。  

---

## 決定木でできること

- **分類**  
  例）年齢・収入などの属性から「購入する／しない」を判定する  
- **回帰**  
  例）部屋の広さや立地から家賃を予測する  
- **特徴量の重要度の把握**  
  どの特徴量が予測に効いているかを確認できる  
- **ルールの解釈**  
  木の分岐をたどることで「なぜその予測になったのか？」を説明できる  

---

## 学ぶ内容の流れ

1. 決定木の基本的な仕組み（ルールの分割と予測）  
2. 分類木と回帰木の違い  
3. パラメータを変えたときの挙動の変化  
4. 過学習を防ぐための工夫（剪定やパラメータ制御）  

---

## まとめ

決定木は「シンプルで直感的」かつ「応用範囲が広い」機械学習モデルです。  
単体でも有用ですが、ランダムフォレストや勾配ブースティングといった強力なモデルの基盤でもあるため、**まず決定木を理解することが後の学習をスムーズにします**。  
可視化がしやすく解釈性が高いため、実務の分析・説明にもよく利用されます。  

> 💡 **ポイント**: 決定木の理解は、アンサンブル学習やさらに高度なモデルの理解にもつながります。
