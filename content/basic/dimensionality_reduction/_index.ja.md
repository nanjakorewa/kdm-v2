---
title: 次元削減
weight: 7
chapter: true
not_use_colab: true
not_use_twitter: true
pre: "<b>2.6 </b>"
---

### Chapter 6

# 次元削減

<div class="pagetop-box">
  <p><b>次元削減（Dimensionality Reduction）</b>とは、多数の特徴量を持つデータから、情報をなるべく失わずに少数の特徴にまとめ直す手法です。  
  現代のデータは高次元（特徴量が多い）であることが多く、そのままでは「扱いづらい・計算が重い・可視化できない」といった問題が生じます。次元削減はこうした課題を解決する重要なステップです。</p>
</div>

---

## なぜ次元削減を学ぶのか？

- **可視化**  
  2次元や3次元に落とし込むことで、人間の目で「データの構造」を直感的に理解できる。  

- **ノイズ除去・特徴圧縮**  
  重要な成分だけを残すことで、不要なノイズや冗長な特徴を削減し、モデルの精度向上や過学習防止につながる。  

- **計算効率の向上**  
  高次元データを低次元に変換することで、計算量を削減でき、学習が速くなる。  

---

## この章で扱う代表的な手法

- **PCA（主成分分析）**  
  データの分散が最大になる方向を探して次元を削減する最も基本的な手法。  

- **SVD（特異値分解）**  
  行列を直交行列と特異値に分解することで、情報量の多い成分を抽出する数学的基盤。  

- **LDA（線形判別分析）**  
  クラスラベルを用い、クラス間の分離を最大化するように次元削減する教師あり手法。  

- **Kernel PCA**  
  PCAを非線形に拡張し、円や渦巻きのような複雑な構造をとらえることができる。  

---

## まとめ
- 次元削減は「高次元データを理解・活用するための鍵」。  
- 可視化・ノイズ除去・高速化など多くのメリットがある。  
- 本章では **PCA → SVD → LDA → Kernel PCA** の流れで、基礎から応用まで体系的に学んでいく。  

---
